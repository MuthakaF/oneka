# ONEKA AI: Predictive Analysis & Change Detection Architecture

## Using Historical Satellite Time-Series to Predict Infrastructure Project Outcomes

---

## Executive Summary

**The Insight**: Satellite data is **immutable and historical**. Unlike financial reports (which may be delayed, manipulated, or unavailable), satellite archives preserve the complete construction timeline of every project going back to 2015 (Sentinel-2) and 2014 (Sentinel-1).

**The Opportunity**: Use **completed projects with known outcomes** as training data to build a **supervised machine learning model** that learns "what does normal construction progress look like" across different project types (hospitals, schools, roads, markets).

**The Innovation**: Train a **change detection algorithm** on historical satellite time-series (pre-construction â†’ construction phases â†’ completion) to create a "Project Health Score" that predicts, in real-time, whether an ongoing project is on track or at risk of becoming a ghost project.

**Key Advantage Over Traditional Audits**: Most fraud is detected 2-3 years after completion when it's too late. ONEKA's predictive model can **flag at-risk projects within 3-6 months of award**, enabling early intervention.

---

## 1. The Predictive Analysis Framework

### 1.1 The Core Concept: Learning from the Past

**Traditional Approach (Reactive)**:

```
Project Awarded â†’ Wait 2 years â†’ Field Audit â†’ Discovery of ghost project â†’ Too late
```

**ONEKA Approach (Predictive)**:

```
Project Awarded â†’ Train ML model on historical data â†’ Monitor first 6 months â†’
Early risk detection â†’ Intervention â†’ Prevent fraud before it scales
```

### 1.2 Why Historical Training Works

**The Hypothesis**: Construction projects follow predictable physical signatures over time that are visible from space.

**Observable Patterns**:

| Phase                   | Typical Duration | Sentinel-2 Signature                 | Sentinel-1 Signature                          | True Color (Google 3D)            |
| ----------------------- | ---------------- | ------------------------------------ | --------------------------------------------- | --------------------------------- |
| **Pre-Construction**    | Month 0          | High NDVI (0.6-0.8, vegetation)      | Low backscatter (-15 to -12 dB)               | Green vegetation visible          |
| **Land Clearing**       | Months 1-2       | NDVI drop (-0.3 to -0.5)             | Slight backscatter increase (-12 to -10 dB)   | Bare soil, cleared area           |
| **Foundation**          | Months 3-5       | Low NDVI (-0.1 to 0.1, bare soil)    | Moderate backscatter (-8 to -6 dB)            | Excavations, concrete pours       |
| **Superstructure**      | Months 6-18      | NDVI ~0 (concrete/metal)             | High backscatter (-5 to +2 dB, metal roofing) | Vertical structures visible       |
| **Completion**          | Months 18-24     | NDVI stable near 0                   | Very high backscatter (0 to +5 dB for metal)  | Completed building, landscaping   |
| **Abandonment (Ghost)** | Any time         | NDVI increases (vegetation regrowth) | Backscatter decreases                         | No structures, vegetation returns |

**The Training Data**: For a hospital project completed in 2022-2023, we can reconstruct its entire timeline using Sentinel archive:

- Award Date: March 2022
- Expected Completion: March 2024 (24 months)
- Reality: Completed December 2023 (21 months, on track)

By querying the Sentinel archive for this site from March 2022 â†’ December 2023, we get:

- **Sentinel-2**: 36-72 cloud-free images (5-day revisit Ã— 2 satellites)
- **Sentinel-1**: 60-72 images (6-day revisit with constellation)

This creates a **time-series ground truth**: "This is what a successful hospital project looks like from space over 21 months."

---

## 2. Data Sources for Training and Prediction

### 2.1 Historical Completed Projects (Training Set)

**Criteria for Training Projects**:

1. âœ… **Known outcome**: Project confirmed completed and operational (verified by field audit or OAG reports)
2. âœ… **GPS coordinates available**: Either from facility registry (KMHFL/MOE) or manual verification
3. âœ… **Financial data available**: Award date, contract sum, completion date from public records
4. âœ… **Timeline documented**: Clear start and end dates (minimum 12 months construction period)
5. âœ… **Project type diversity**: Mix of health, education, roads, water, markets

**Target Training Set Size**:

- **Minimum Viable**: 30 projects (10 health, 10 education, 10 roads/markets)
- **Optimal**: 100+ projects across multiple sectors
- **Gold Standard**: 500+ projects for robust sector-specific models

**Example Training Projects** (Verified & Documented):

| Project Name                      | Type      | Location       | Award Date | Completion Date   | Duration  | Outcome      | Financial Data | GPS              |
| --------------------------------- | --------- | -------------- | ---------- | ----------------- | --------- | ------------ | -------------- | ---------------- |
| Kiambu Level 5 Hospital Expansion | Health    | Kiambu County  | Jan 2021   | Dec 2022          | 24 months | âœ… Completed | KES 450M       | -1.1714, 36.8356 |
| Githunguri Secondary School       | Education | Kiambu County  | Mar 2021   | Aug 2022          | 17 months | âœ… Completed | KES 85M        | -1.0534, 36.7842 |
| Thika Road Flyover Extension      | Roads     | Nairobi County | Jun 2020   | Mar 2022          | 21 months | âœ… Completed | KES 1.2B       | -1.2345, 36.8912 |
| Nakuru Market Modernization       | Markets   | Nakuru County  | Feb 2021   | Oct 2022          | 20 months | âœ… Completed | KES 120M       | -0.3031, 36.0800 |
| Mombasa Dispensary Construction   | Health    | Mombasa County | Sep 2020   | Feb 2022          | 17 months | âœ… Completed | KES 65M        | -4.0435, 39.6682 |
| **Kajiado Ghost Hospital**        | Health    | Kajiado County | Apr 2021   | Never (abandoned) | 0 months  | âŒ Ghost     | KES 280M       | -1.8523, 36.7820 |

**Key Insight**: The ghost project (Kajiado Hospital) serves as **negative training data** - showing what abandonment looks like (NDVI increases, no backscatter change).

---

### 2.2 Satellite Layer Selection for Change Detection

Different satellite indices reveal different aspects of construction activity. For ONEKA, we need a **multi-spectral approach**.

#### **Recommended Layer Stack**:

##### **Layer 1: True Colour Composite (RGB - Sentinel-2 B4, B3, B2)**

**Purpose**: Human-interpretable visual confirmation of construction activity.

**Bands Used**:

- Red: Band 4 (665 nm) - 10m resolution
- Green: Band 3 (560 nm) - 10m resolution
- Blue: Band 2 (490 nm) - 10m resolution

**What It Shows**:

- Vegetation appears green
- Bare soil appears brown/tan
- Concrete appears gray
- Water appears blue/black
- Metal roofing appears bright white/silver

**Use Case**:

- **Validation layer** for algorithm results
- **Human verification** when ML model flags anomaly
- **Public-facing visualization** for non-technical stakeholders (media, parliament, citizens)

**Satpy Code**:

```python
from satpy import Scene
from datetime import datetime

def get_true_color_composite(latitude, longitude, date):
    """
    Extract true color RGB composite for visualization
    """
    # Load Sentinel-2 scene
    scene = Scene(reader='msi_safe', filenames=find_sentinel2_files(latitude, longitude, date))

    # Load RGB bands
    scene.load(['B04', 'B03', 'B02'])

    # Create true color composite
    scene.save_dataset('true_color',
                      filename=f'truecolor_{date}.png',
                      datasets=['B04', 'B03', 'B02'])

    return scene
```

**Training Use**: Label training images manually: "Month 3 - land cleared", "Month 12 - structure visible"

---

##### **Layer 2: False Colour Composite (NIR-Red-Green - Sentinel-2 B8, B4, B3)**

**Purpose**: Emphasize vegetation health and distinguish construction materials from natural features.

**Bands Used**:

- NIR (Near-Infrared): Band 8 (842 nm) - 10m resolution
- Red: Band 4 (665 nm) - 10m resolution
- Green: Band 3 (560 nm) - 10m resolution

**What It Shows**:

- **Healthy vegetation appears bright red** (high NIR reflectance)
- **Bare soil appears brown/gray**
- **Water appears dark blue/black**
- **Concrete/buildings appear cyan/light blue**
- **Recently cleared land appears very dark** (no vegetation, no NIR response)

**Use Case**:

- **Land clearing detection**: Dramatic color change from red (vegetation) to dark (bare soil) in Months 1-2
- **Distinguish construction from natural bare soil**: Construction sites have sharper boundaries
- **Detect vegetation regrowth** (abandonment indicator): Area transitions back to red

**Satpy Code**:

```python
def get_false_color_composite(latitude, longitude, date):
    """
    False color composite emphasizing vegetation
    """
    scene = Scene(reader='msi_safe', filenames=find_sentinel2_files(latitude, longitude, date))

    # Load NIR, Red, Green
    scene.load(['B08', 'B04', 'B03'])

    # Create false color composite
    scene.save_dataset('false_color',
                      filename=f'falsecolor_{date}.png',
                      datasets=['B08', 'B04', 'B03'])

    return scene
```

**Training Use**: Calculate "redness loss" as proxy for construction activity. Train model to recognize temporary vs permanent bare soil.

---

##### **Layer 3: NDVI (Normalized Difference Vegetation Index) - PRIMARY CHANGE DETECTION**

**Purpose**: Quantitative measurement of vegetation health/density for automated change detection.

**Formula**:

```
NDVI = (NIR - Red) / (NIR + Red)
     = (B8 - B4) / (B8 + B4)
```

**Value Range**:

- **+0.6 to +0.9**: Dense healthy vegetation (forests, farms, grasslands)
- **+0.2 to +0.5**: Sparse vegetation (shrubs, degraded grassland)
- **-0.1 to +0.1**: Bare soil, rock, sand
- **-0.1 to -0.3**: Water, concrete, asphalt
- **Below -0.3**: Anomalies (usually cloud shadow or water)

**Construction Phases & NDVI**:

| Phase                           | Expected NDVI                            | Change from Baseline    | Detection Threshold       |
| ------------------------------- | ---------------------------------------- | ----------------------- | ------------------------- |
| **Pre-Construction (Baseline)** | +0.5 to +0.7 (typical Kenyan vegetation) | 0 (reference)           | N/A                       |
| **Land Clearing (Month 1-2)**   | +0.1 to +0.3                             | **-0.4 to -0.5**        | Alert if drop > 0.3       |
| **Foundation (Month 3-5)**      | -0.1 to +0.1                             | -0.6 to -0.7            | Confirms construction     |
| **Construction (Month 6-18)**   | -0.1 to 0                                | -0.6 to -0.8            | Expected (concrete/metal) |
| **Completion (Month 18+)**      | -0.1 to 0 (stable)                       | Stable at -0.7          | Success indicator         |
| **Abandonment (Ghost)**         | +0.3 to +0.5 (regrowth)                  | **Returns toward +0.5** | ðŸš¨ Ghost project alert    |

**Critical Insight**: **NDVI "rebounds" are the smoking gun for ghost projects**. If NDVI drops (land cleared) then increases back toward baseline (vegetation regrows), construction was abandoned.

**Satpy Code**:

```python
import numpy as np

def calculate_ndvi_timeseries(latitude, longitude, start_date, end_date):
    """
    Calculate NDVI time series for project monitoring
    Returns: DataFrame with dates and NDVI values
    """
    dates = generate_date_range(start_date, end_date, interval_days=12)  # Sentinel-1 revisit
    ndvi_values = []

    for date in dates:
        # Find cloud-free Sentinel-2 scene
        scene = Scene(reader='msi_safe',
                     filenames=find_sentinel2_files(latitude, longitude, date,
                                                    max_cloud_cover=20))

        # Load NIR and Red bands
        scene.load(['B08', 'B04'])

        # Calculate NDVI
        nir = scene['B08'].values
        red = scene['B04'].values

        ndvi = (nir - red) / (nir + red + 1e-8)  # Add epsilon to avoid division by zero

        # Extract mean NDVI for 100m buffer around project site
        site_ndvi = extract_buffer_stats(ndvi, latitude, longitude, radius_m=100)

        ndvi_values.append({
            'date': date,
            'ndvi_mean': site_ndvi['mean'],
            'ndvi_std': site_ndvi['std'],
            'ndvi_min': site_ndvi['min'],
            'ndvi_max': site_ndvi['max']
        })

    return pd.DataFrame(ndvi_values)
```

**Training Use**: **PRIMARY FEATURE VECTOR**. Feed NDVI time series into ML model. Successful projects show: High â†’ Drop â†’ Stable Low. Ghost projects show: High â†’ Drop â†’ Rebound.

---

##### **Layer 4: NDWI (Normalized Difference Water Index) - COMPLEMENTARY**

**Purpose**: Detect water bodies and wet surfaces to avoid false positives from seasonal flooding or irrigation.

**Formula**:

```
NDWI = (Green - NIR) / (Green + NIR)
     = (B3 - B8) / (B3 + B8)
```

**Value Range**:

- **+0.3 to +1.0**: Water bodies (lakes, rivers, ponds)
- **+0.0 to +0.2**: Wet soil, irrigated fields
- **-0.1 to -0.3**: Dry soil, vegetation
- **Below -0.3**: Dry bare surfaces, buildings

**Why It Matters for ONEKA**:
Kenya has distinct rainy seasons (March-May, October-December). Without NDWI filtering, seasonal flooding could be misinterpreted as land clearing:

- **False Positive Scenario**: NDVI drops in March (rainy season, flooded site) â†’ Algorithm thinks land was cleared â†’ False alert
- **NDWI Correction**: High NDWI (+0.3) indicates flooding, not construction â†’ Filter out this date from analysis

**Use Case**:

- **Filter false positives**: If NDVI drops but NDWI is high, it's flooding, not construction
- **Detect water/drainage infrastructure**: For road/drainage projects, NDWI helps verify completion
- **Quality control**: Exclude waterlogged images from NDVI time series

**Satpy Code**:

```python
def calculate_ndwi(scene):
    """
    Calculate NDWI to detect water and filter false positives
    """
    scene.load(['B03', 'B08'])

    green = scene['B03'].values
    nir = scene['B08'].values

    ndwi = (green - nir) / (green + nir + 1e-8)

    return ndwi

def filter_flooded_dates(ndvi_timeseries, latitude, longitude):
    """
    Remove dates where NDWI indicates flooding
    """
    filtered = []

    for record in ndvi_timeseries:
        date = record['date']
        scene = load_scene(latitude, longitude, date)
        ndwi = calculate_ndwi(scene)

        site_ndwi = extract_buffer_stats(ndwi, latitude, longitude, radius_m=100)['mean']

        # Exclude if site is flooded (NDWI > 0.2)
        if site_ndwi < 0.2:
            filtered.append(record)
        else:
            print(f"Excluding {date}: NDWI={site_ndwi:.2f} indicates flooding")

    return filtered
```

---

##### **Layer 5: SAR Backscatter (Sentinel-1 VV/VH) - ALL-WEATHER BACKBONE**

**Purpose**: Cloud-penetrating radar to ensure continuous monitoring during rainy seasons when optical data fails.

**Polarizations**:

- **VV (Vertical-Vertical)**: Best for detecting man-made structures (walls, buildings)
- **VH (Vertical-Horizontal)**: Best for vegetation and surface roughness

**Backscatter Values (dB)**:

| Surface Type       | VV Backscatter  | VH Backscatter | Construction Phase  |
| ------------------ | --------------- | -------------- | ------------------- |
| Dense vegetation   | -15 to -12 dB   | -22 to -18 dB  | Pre-construction    |
| Bare soil (rough)  | -10 to -8 dB    | -18 to -15 dB  | Land clearing       |
| Bare soil (smooth) | -12 to -10 dB   | -20 to -17 dB  | Foundation prep     |
| Concrete (wet)     | -8 to -5 dB     | -15 to -12 dB  | Active construction |
| Metal roofing      | **-2 to +3 dB** | -10 to -8 dB   | **Completion**      |
| Water              | -20 to -15 dB   | -25 to -22 dB  | Flooding (filter)   |

**Critical Pattern**: **VV backscatter increases dramatically** when vertical metal structures (roofing, walls) are erected due to "double bounce" effect (radar signal bounces between ground and vertical surface).

**PyroSAR Code**:

```python
from pyroSAR import identify, geocode
from pyroSAR.snap import geocode

def process_sentinel1_timeseries(latitude, longitude, start_date, end_date):
    """
    Process Sentinel-1 SAR for all-weather change detection
    """
    # Define AOI
    aoi = create_bbox(latitude, longitude, buffer_km=1)

    # Download Sentinel-1 scenes
    scenes = download_sentinel1(aoi, start_date, end_date, product_type='GRD')

    backscatter_values = []

    for scene_path in scenes:
        # Identify scene
        scene_id = identify(scene_path)

        # Geocode (radiometric terrain correction + geocoding)
        geocode(infile=scene_path,
               outdir='processed/',
               t_srs=4326,  # WGS84
               spacing=10,  # 10m resolution
               polarizations=['VV', 'VH'],
               scaling='dB',  # Convert to decibels
               remove_border_noise=True)

        # Extract backscatter statistics
        vv_tif = f'processed/{scene_id.scene}_VV.tif'
        vh_tif = f'processed/{scene_id.scene}_VH.tif'

        vv_stats = extract_buffer_stats(vv_tif, latitude, longitude, radius_m=100)
        vh_stats = extract_buffer_stats(vh_tif, latitude, longitude, radius_m=100)

        backscatter_values.append({
            'date': scene_id.start,
            'vv_mean': vv_stats['mean'],
            'vh_mean': vh_stats['mean'],
            'vv_std': vv_stats['std']
        })

    return pd.DataFrame(backscatter_values)
```

**Training Use**: **SECONDARY FEATURE VECTOR**. SAR backscatter complements NDVI:

- If NDVI drops (land clearing) AND VV backscatter increases â†’ High confidence construction
- If NDVI stable but VV backscatter increases â†’ Vertical structures added (superstructure phase)
- If NDVI rebounds AND VV backscatter decreases â†’ Abandonment confirmed

---

### 2.3 Recommended Multi-Layer Strategy for ONEKA

**For Training (Historical Projects)**:

1. âœ… **NDVI**: Primary feature (quantitative vegetation change)
2. âœ… **SAR VV Backscatter**: Secondary feature (structure detection, all-weather)
3. âœ… **False Color Composite**: Manual labeling of construction phases
4. âœ… **NDWI**: Quality control filter (remove flooded dates)
5. âš ï¸ **True Color**: Human validation only (too subjective for ML)

**For Real-Time Prediction (Ongoing Projects)**:

1. âœ… **NDVI**: Every 6 days (Sentinel-2 constellation)
2. âœ… **SAR VV**: Every 6 days (Sentinel-1 constellation, cloud backup)
3. âœ… **NDWI**: Monthly (to filter rainy season false positives)
4. âœ… **True Color**: Quarterly (for dashboard visualization and public reports)

**Cost Optimization**:

- Sentinel data (all layers): **FREE via Copernicus**
- Processing compute (AWS Fargate): ~$5/month for 50 projects
- Storage (S3): ~$2/month for time-series GeoTIFFs

---

## 3. The Change Detection Algorithm

### 3.1 Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HISTORICAL TRAINING PHASE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  100 Completed   â”‚          â”‚  10 Ghost/       â”‚
    â”‚  Projects        â”‚          â”‚  Abandoned       â”‚
    â”‚  (Successful)    â”‚          â”‚  Projects        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                               â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Satellite Time-Series       â”‚
              â”‚  Extraction:                 â”‚
              â”‚  â€¢ NDVI (every 6 days)       â”‚
              â”‚  â€¢ SAR VV (every 6 days)     â”‚
              â”‚  â€¢ NDWI (monthly filter)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Feature Engineering:        â”‚
              â”‚  â€¢ NDVI slope                â”‚
              â”‚  â€¢ NDVI variance             â”‚
              â”‚  â€¢ SAR backscatter change    â”‚
              â”‚  â€¢ Phase detection           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  ML Model Training:          â”‚
              â”‚  Random Forest Classifier    â”‚
              â”‚  Predict: ON_TRACK vs GHOST  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  REAL-TIME PREDICTION PHASE                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  New Project Awarded         â”‚
              â”‚  (e.g., Hospital XYZ)        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Monitor Monthly (Months 1-6)â”‚
              â”‚  Extract NDVI + SAR          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Compare to Trained Patterns â”‚
              â”‚  Predict Risk Score          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  LOW RISK  â”‚  â”‚ MEDIUM RISKâ”‚  â”‚  HIGH RISK â”‚
      â”‚  (On track)â”‚  â”‚  (Delayed) â”‚  â”‚  (Ghost)   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  ALERT OAG       â”‚
                                    â”‚  Suspend Payment â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3.2 Feature Engineering from Satellite Time-Series

For each project, extract time-series features from satellite data:

#### **Feature Set 1: NDVI-Based Features**

```python
def extract_ndvi_features(ndvi_timeseries, project_duration_months):
    """
    Extract statistical features from NDVI time series
    """
    features = {}

    # 1. Baseline NDVI (pre-construction)
    features['ndvi_baseline'] = ndvi_timeseries[0]['ndvi_mean']

    # 2. Maximum NDVI drop (land clearing magnitude)
    ndvi_values = [d['ndvi_mean'] for d in ndvi_timeseries]
    features['ndvi_max_drop'] = features['ndvi_baseline'] - min(ndvi_values)

    # 3. NDVI slope (rate of change)
    dates = [d['date'] for d in ndvi_timeseries]
    time_numeric = [(d - dates[0]).days for d in dates]
    slope, intercept = np.polyfit(time_numeric, ndvi_values, 1)
    features['ndvi_slope'] = slope

    # 4. NDVI variance (stability indicator)
    features['ndvi_variance'] = np.var(ndvi_values)

    # 5. NDVI recovery (ghost project indicator)
    # If NDVI drops then returns to >50% of baseline, it's abandoned
    final_ndvi = ndvi_timeseries[-1]['ndvi_mean']
    recovery_ratio = final_ndvi / features['ndvi_baseline']
    features['ndvi_recovery_ratio'] = recovery_ratio

    # 6. Time to land clearing (how fast did NDVI drop?)
    drop_threshold = features['ndvi_baseline'] - 0.3
    months_to_clearing = 0
    for i, record in enumerate(ndvi_timeseries):
        if record['ndvi_mean'] < drop_threshold:
            months_to_clearing = i
            break
    features['months_to_clearing'] = months_to_clearing

    # 7. NDVI stability period (how long has NDVI been stable?)
    # Count consecutive months with NDVI within 0.1 of each other
    stable_months = 0
    for i in range(1, len(ndvi_values)):
        if abs(ndvi_values[i] - ndvi_values[i-1]) < 0.1:
            stable_months += 1
        else:
            stable_months = 0
    features['ndvi_stable_months'] = stable_months

    return features
```

#### **Feature Set 2: SAR Backscatter Features**

```python
def extract_sar_features(sar_timeseries):
    """
    Extract features from Sentinel-1 SAR backscatter
    """
    features = {}

    vv_values = [d['vv_mean'] for d in sar_timeseries]

    # 1. Baseline backscatter
    features['sar_baseline'] = vv_values[0]

    # 2. Maximum backscatter increase (structure detection)
    features['sar_max_increase'] = max(vv_values) - features['sar_baseline']

    # 3. SAR slope (construction rate)
    dates = [d['date'] for d in sar_timeseries]
    time_numeric = [(d - dates[0]).days for d in dates]
    sar_slope, _ = np.polyfit(time_numeric, vv_values, 1)
    features['sar_slope'] = sar_slope

    # 4. Final backscatter (completion indicator)
    # Metal roofing should push VV > -5 dB
    features['sar_final'] = vv_values[-1]

    # 5. Month of maximum backscatter (when did structures appear?)
    features['month_of_max_backscatter'] = np.argmax(vv_values)

    return features
```

#### **Feature Set 3: Cross-Spectral Features**

```python
def extract_cross_spectral_features(ndvi_features, sar_features):
    """
    Features combining NDVI and SAR
    """
    features = {}

    # 1. NDVI-SAR correlation
    # Successful projects: NDVI drops â†’ SAR increases (inverse correlation)
    # Ghost projects: NDVI rebounds â†’ SAR stable (no correlation)
    features['ndvi_sar_correlation'] = calculate_correlation(ndvi_values, sar_values)

    # 2. Construction consistency score
    # High score: NDVI dropped AND SAR increased
    # Low score: NDVI dropped but SAR didn't increase (land cleared but nothing built)
    if ndvi_features['ndvi_max_drop'] > 0.3 and sar_features['sar_max_increase'] > 5:
        features['construction_consistency'] = 1.0  # Strong evidence
    elif ndvi_features['ndvi_max_drop'] > 0.3 and sar_features['sar_max_increase'] < 2:
        features['construction_consistency'] = 0.2  # Suspicious (land cleared, no building)
    else:
        features['construction_consistency'] = 0.5  # Uncertain

    return features
```

#### **Feature Set 4: Temporal Features**

```python
def extract_temporal_features(project_timeline, ndvi_timeseries, contract_months):
    """
    Time-based features comparing actual vs expected progress
    """
    features = {}

    # 1. Elapsed time since award (in months)
    features['months_elapsed'] = len(ndvi_timeseries)

    # 2. Expected completion percentage
    features['expected_progress_pct'] = (features['months_elapsed'] / contract_months) * 100

    # 3. Actual physical progress (estimated from satellite)
    # Use simple heuristics:
    # - NDVI dropped > 0.3: 30% (land clearing)
    # - SAR increased > 5 dB: +40% (structures)
    # - SAR > -5 dB (metal detected): +30% (roofing)
    current_ndvi = ndvi_timeseries[-1]['ndvi_mean']
    baseline_ndvi = ndvi_timeseries[0]['ndvi_mean']

    if (baseline_ndvi - current_ndvi) > 0.3:
        physical_progress = 30  # Land cleared
    else:
        physical_progress = 0

    # Add SAR-based progress if available
    if 'sar_final' in features and features['sar_final'] > -5:
        physical_progress += 70  # Structures + roofing
    elif 'sar_max_increase' in features and features['sar_max_increase'] > 5:
        physical_progress += 40  # Structures only

    features['physical_progress_pct'] = min(physical_progress, 100)

    # 4. Progress gap (expected vs actual)
    features['progress_gap'] = features['expected_progress_pct'] - features['physical_progress_pct']

    return features
```

---

### 3.3 Machine Learning Model Training

#### **Model Choice: Random Forest Classifier**

**Why Random Forest?**

- âœ… Handles non-linear relationships (NDVI patterns are non-linear)
- âœ… Robust to outliers (cloud artifacts, seasonal noise)
- âœ… Feature importance ranking (tells us which indices matter most)
- âœ… Works well with small datasets (30-100 training projects)
- âœ… Interpretable for non-technical stakeholders

**Training Code**:

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import joblib

def train_change_detection_model(training_projects):
    """
    Train ML model on historical completed projects

    Args:
        training_projects: List of dicts with:
            - project_uuid
            - satellite_timeseries (NDVI + SAR)
            - outcome: 'COMPLETED' or 'GHOST'
            - timeline_months

    Returns:
        Trained model
    """

    # Step 1: Extract features for all training projects
    X = []  # Feature vectors
    y = []  # Labels

    for project in training_projects:
        # Extract satellite data
        ndvi_ts = project['ndvi_timeseries']
        sar_ts = project['sar_timeseries']

        # Engineer features
        ndvi_feats = extract_ndvi_features(ndvi_ts, project['timeline_months'])
        sar_feats = extract_sar_features(sar_ts)
        cross_feats = extract_cross_spectral_features(ndvi_feats, sar_feats)
        temporal_feats = extract_temporal_features(project['timeline_months'],
                                                   ndvi_ts,
                                                   project['contract_months'])

        # Combine all features
        feature_vector = {**ndvi_feats, **sar_feats, **cross_feats, **temporal_feats}
        X.append(list(feature_vector.values()))

        # Label
        if project['outcome'] == 'COMPLETED':
            y.append(1)  # Successful project
        else:
            y.append(0)  # Ghost/abandoned project

    X = np.array(X)
    y = np.array(y)

    # Step 2: Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
                                                         stratify=y,
                                                         random_state=42)

    # Step 3: Train Random Forest
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        random_state=42,
        class_weight='balanced'  # Handle imbalanced data (fewer ghost projects)
    )

    model.fit(X_train, y_train)

    # Step 4: Evaluate
    y_pred = model.predict(X_test)
    print("Classification Report:")
    print(classification_report(y_test, y_pred,
                                target_names=['Ghost/Abandoned', 'Completed']))

    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

    # Step 5: Feature importance
    feature_names = list(feature_vector.keys())
    importances = model.feature_importances_

    print("\nTop 10 Most Important Features:")
    indices = np.argsort(importances)[::-1][:10]
    for i in indices:
        print(f"{feature_names[i]}: {importances[i]:.4f}")

    # Step 6: Cross-validation
    cv_scores = cross_val_score(model, X, y, cv=5, scoring='f1')
    print(f"\nCross-Validation F1 Score: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})")

    # Step 7: Save model
    joblib.dump(model, 'oneka_change_detection_model.pkl')
    joblib.dump(feature_names, 'oneka_feature_names.pkl')

    return model, feature_names
```

**Expected Performance (with 100 training projects)**:

- **Accuracy**: 85-90%
- **Precision** (Ghost projects): 75-80% (minimize false alarms)
- **Recall** (Ghost projects): 80-85% (catch most fraud)
- **F1 Score**: 0.77-0.82

---

### 3.4 Real-Time Prediction Pipeline

```python
def predict_project_risk(project_uuid, model, feature_names):
    """
    Predict risk score for ongoing project
    """

    # Step 1: Get project data
    project = db.projects.get(project_uuid)
    award_date = project.award_date
    current_date = datetime.now()
    months_elapsed = (current_date - award_date).days / 30

    # Step 2: Extract satellite time series
    geolocation = project.geolocation_records[0]
    lat, lon = geolocation.latitude, geolocation.longitude

    ndvi_ts = calculate_ndvi_timeseries(lat, lon, award_date, current_date)
    sar_ts = process_sentinel1_timeseries(lat, lon, award_date, current_date)

    # Step 3: Engineer features
    ndvi_feats = extract_ndvi_features(ndvi_ts, months_elapsed)
    sar_feats = extract_sar_features(sar_ts)
    cross_feats = extract_cross_spectral_features(ndvi_feats, sar_feats)
    temporal_feats = extract_temporal_features(months_elapsed,
                                              ndvi_ts,
                                              project.contract_months)

    feature_vector = {**ndvi_feats, **sar_feats, **cross_feats, **temporal_feats}
    X = np.array([list(feature_vector.values())])

    # Step 4: Predict
    prediction = model.predict(X)[0]
    probability = model.predict_proba(X)[0]

    # Step 5: Calculate risk score
    ghost_probability = probability[0]  # Probability of being ghost project
    risk_score = ghost_probability * 100

    # Step 6: Determine risk level
    if risk_score > 70:
        risk_level = 'HIGH'
        risk_interpretation = "Very high likelihood of abandonment or fraud. Immediate field audit recommended."
    elif risk_score > 40:
        risk_level = 'MEDIUM'
        risk_interpretation = "Delayed progress detected. Monitor closely and request contractor progress report."
    else:
        risk_level = 'LOW'
        risk_interpretation = "Project on track. Continue routine monitoring."

    # Step 7: Store prediction
    db.ml_predictions.insert({
        'project_uuid': project_uuid,
        'model_version': '1.0',
        'prediction_date': current_date,
        'risk_score': risk_score,
        'risk_level': risk_level,
        'ghost_probability': ghost_probability,
        'completed_probability': probability[1],
        'interpretation': risk_interpretation,
        'months_analyzed': months_elapsed,
        'feature_vector': feature_vector
    })

    return {
        'risk_score': risk_score,
        'risk_level': risk_level,
        'interpretation': risk_interpretation
    }
```

---

## 4. Integration with Google 3D Tiles

### 4.1 Why Combine Satellite Data with Google 3D Tiles?

**Satellite Data (Sentinel) Strengths**:

- âœ… Temporally dense (every 6 days)
- âœ… Free and unlimited
- âœ… Quantitative change detection
- âœ… Works in rural areas

**Satellite Data Limitations**:

- âŒ 10m resolution insufficient for small details
- âŒ Not intuitive for non-technical users
- âŒ Requires spectral analysis expertise

**Google 3D Tiles Strengths**:

- âœ… High resolution (1m RGB, 3D buildings)
- âœ… Highly intuitive (looks like reality)
- âœ… Shows urban context (roads, landmarks)
- âœ… 3D buildings show height/volume

**Google 3D Tiles Limitations**:

- âŒ Not temporally updated (static or slow refresh)
- âŒ Requires API credits ($7/1000 requests)
- âŒ Limited to urban areas (no 3D in rural Kenya)

**The Hybrid Approach**: Use **Sentinel for change detection**, then **Google 3D Tiles for human verification and public visualization**.

---

### 4.2 Technical Integration Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ONEKA FRONTEND (React + CesiumJS)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google 3D     â”‚  â”‚  Sentinel  â”‚  â”‚  Risk Indicators  â”‚
â”‚  Tiles Base    â”‚  â”‚  Overlays  â”‚  â”‚  (Colored Pins)   â”‚
â”‚  Layer         â”‚  â”‚            â”‚  â”‚                   â”‚
â”‚  (Buildings)   â”‚  â”‚  â€¢ NDVI    â”‚  â”‚  â€¢ Green (Low)    â”‚
â”‚                â”‚  â”‚  â€¢ SAR     â”‚  â”‚  â€¢ Yellow (Med)   â”‚
â”‚                â”‚  â”‚  â€¢ True    â”‚  â”‚  â€¢ Red (High)     â”‚
â”‚                â”‚  â”‚    Color   â”‚  â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4.3 Implementation: CesiumJS with Multi-Layer Visualization

```javascript
// frontend/src/components/ProjectMap.jsx
import { Viewer, ImageryLayer, Entity, PointGraphics } from "resium";
import {
  Cartesian3,
  Color,
  UrlTemplateImageryProvider,
  GoogleMaps,
} from "cesium";

function ProjectMap({ projects, selectedProject }) {
  // Base layer: Google 3D Tiles (Photorealistic)
  const google3DTilesProvider = new GoogleMaps({
    mapId: process.env.REACT_APP_GOOGLE_MAP_ID, // Your Google Cloud Map ID
    mapType: GoogleMaps.MapType.AERIAL, // Satellite imagery
  });

  // Overlay 1: Sentinel-2 NDVI (semi-transparent)
  const ndviProvider = new UrlTemplateImageryProvider({
    url: "https://oneka-tiles.s3.amazonaws.com/ndvi/{z}/{x}/{y}.png",
    maximumLevel: 15,
    alpha: 0.5, // 50% transparency to see buildings underneath
  });

  // Overlay 2: Sentinel-1 SAR Backscatter
  const sarProvider = new UrlTemplateImageryProvider({
    url: "https://oneka-tiles.s3.amazonaws.com/sar/{z}/{x}/{y}.png",
    maximumLevel: 15,
    alpha: 0.4,
  });

  // Function to get project pin color based on risk
  const getRiskColor = (risk_level) => {
    switch (risk_level) {
      case "HIGH":
        return Color.RED;
      case "MEDIUM":
        return Color.YELLOW;
      case "LOW":
        return Color.GREEN;
      default:
        return Color.GRAY;
    }
  };

  return (
    <Viewer full>
      {/* Base Layer: Google 3D Tiles */}
      <ImageryLayer imageryProvider={google3DTilesProvider} />

      {/* Overlay: NDVI (toggle-able) */}
      {showNDVI && <ImageryLayer imageryProvider={ndviProvider} alpha={0.5} />}

      {/* Overlay: SAR (toggle-able) */}
      {showSAR && <ImageryLayer imageryProvider={sarProvider} alpha={0.4} />}

      {/* Project Markers */}
      {projects.map((project) => {
        const position = Cartesian3.fromDegrees(
          project.longitude,
          project.latitude,
          100, // 100m above ground
        );

        return (
          <Entity
            key={project.project_uuid}
            position={position}
            onClick={() => handleProjectClick(project)}
          >
            <PointGraphics
              pixelSize={project.uuid === selectedProject?.uuid ? 20 : 12}
              color={getRiskColor(project.risk_level)}
              outlineColor={Color.WHITE}
              outlineWidth={2}
            />
          </Entity>
        );
      })}

      {/* Selected Project: Show NDVI Time Series Chart */}
      {selectedProject && <ProjectDetailPanel project={selectedProject} />}
    </Viewer>
  );
}
```

---

### 4.4 Satellite Tile Generation Pipeline

To overlay Sentinel data on Google 3D Tiles, we need to convert GeoTIFFs to map tiles (XYZ format).

```python
# backend/satellite/tile_generator.py
import rasterio
from rasterio.warp import calculate_default_transform, reproject, Resampling
import mercantile
import numpy as np
from PIL import Image

def generate_ndvi_tiles(ndvi_geotiff_path, output_dir, zoom_levels=[12, 13, 14, 15]):
    """
    Convert NDVI GeoTIFF to XYZ tiles for web display
    """
    with rasterio.open(ndvi_geotiff_path) as src:
        # Get bounds
        bounds = src.bounds

        for zoom in zoom_levels:
            # Get tiles covering this area at this zoom
            tiles = list(mercantile.tiles(bounds.left, bounds.bottom,
                                         bounds.right, bounds.top, zoom))

            for tile in tiles:
                # Get tile bounds in lat/lon
                tile_bounds = mercantile.bounds(tile)

                # Read NDVI data for this tile
                window = rasterio.windows.from_bounds(
                    tile_bounds.west, tile_bounds.south,
                    tile_bounds.east, tile_bounds.north,
                    src.transform
                )

                ndvi_data = src.read(1, window=window)

                # Normalize NDVI (-1 to 1) to RGB for visualization
                # Red: -1 to -0.2 (water/concrete)
                # Yellow: -0.2 to 0.2 (bare soil)
                # Green: 0.2 to 1.0 (vegetation)
                rgb_tile = ndvi_to_rgb(ndvi_data)

                # Save as PNG tile
                tile_path = f"{output_dir}/{zoom}/{tile.x}/{tile.y}.png"
                os.makedirs(os.path.dirname(tile_path), exist_ok=True)

                img = Image.fromarray(rgb_tile)
                img.save(tile_path)

def ndvi_to_rgb(ndvi, colormap='RdYlGn'):
    """
    Convert NDVI values to RGB for visualization
    """
    # Normalize NDVI from [-1, 1] to [0, 255]
    ndvi_normalized = ((ndvi + 1) / 2 * 255).astype(np.uint8)

    # Apply colormap
    from matplotlib import cm
    cmap = cm.get_cmap(colormap)
    rgb = cmap(ndvi_normalized / 255.0)[:, :, :3] * 255

    return rgb.astype(np.uint8)
```

---

### 4.5 User Experience: The Unified Visualization

**Scenario: Auditor investigates Githurai Hospital**

**Step 1**: Search "Githurai Hospital" â†’ Map zooms to location

**Step 2**: Base layer shows Google 3D Tiles (current state, buildings visible)

**Step 3**: Toggle NDVI overlay â†’ Semi-transparent red heatmap appears showing NO vegetation loss (suspicious for 2-year "construction" project)

**Step 4**: Toggle SAR overlay â†’ Backscatter overlay shows -12 dB (bare soil, no structures)

**Step 5**: Click project pin â†’ Side panel opens:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  GITHURAI HOSPITAL - SATELLITE TIMELINE                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[NDVI Time Series Chart]
  0.7 â”‚   â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—  â† Vegetation stable (NO CLEARING)
  0.5 â”‚                     â† Expected drop to here by Month 2
  0.3 â”‚
  0.1 â”‚
 -0.1 â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       M0  M3  M6  M9  M12 M15 M18 M21 M24

[SAR Backscatter Chart]
  +2  â”‚
  -2  â”‚
  -6  â”‚
 -10  â”‚  â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—  â† Backscatter stable (NO BUILDING)
 -14  â”‚                    â† Expected rise to -5 dB by Month 12
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       M0  M3  M6  M9  M12 M15 M18 M21 M24

ðŸ”´ ML MODEL PREDICTION:
Risk Score: 92/100
Ghost Probability: 92%
Interpretation: "No land clearing detected despite KES 270M disbursed.
Vegetation remains intact. Backscatter shows no structures.
HIGH CONFIDENCE ghost project."

[View Time-Lapse] [Download Report] [Flag for Audit]
```

**Step 6**: Click "View Time-Lapse" â†’ Animation shows:

- Month 0: Green vegetation (Google 3D Tiles + NDVI overlay)
- Month 6: Still green (SHOULD be brown/cleared)
- Month 12: Still green (SHOULD have structures)
- Month 24: Still green (CONFIRMED ghost)

---

## 5. MVP Implementation Roadmap

### Phase 1: Historical Data Collection (Weeks 1-2)

**Objective**: Build training dataset of 30-50 completed projects.

**Tasks**:

1. âœ… Identify 30 completed projects with known outcomes
   - 20 successful (confirmed operational)
   - 10 ghost/abandoned (confirmed fraud from OAG reports)
2. âœ… Geolocate projects using KMHFL/MOE databases
3. âœ… Extract satellite time series for each project:
   - Sentinel-2 NDVI (every 12 days, cloud-filtered)
   - Sentinel-1 SAR VV (every 12 days)
   - Save as CSV: date, ndvi_mean, sar_vv_mean
4. âœ… Manual labeling of construction phases:
   - Load false color composites in QGIS
   - Label: "Month 2 - Land Clearing", "Month 8 - Foundation", etc.

**Deliverable**: `training_data.csv` with 30 projects Ã— 24 months = 720 data points

---

### Phase 2: Model Training (Week 3)

**Objective**: Train Random Forest classifier on historical data.

**Tasks**:

1. âœ… Feature engineering pipeline (NDVI slope, SAR change, etc.)
2. âœ… Train Random Forest model (100 estimators)
3. âœ… Cross-validation (5-fold)
4. âœ… Evaluate metrics (precision, recall, F1)
5. âœ… Save model: `oneka_change_detection_model.pkl`

**Success Criteria**:

- F1 Score > 0.75 for ghost project detection
- Recall > 0.80 (catch 80%+ of fraud cases)

**Deliverable**: Trained model file + feature importance report

---

### Phase 3: Real-Time Pipeline (Weeks 4-5)

**Objective**: Deploy model to predict ongoing projects.

**Tasks**:

1. âœ… Automate satellite data extraction for current projects
2. âœ… Schedule monthly predictions (AWS Lambda cron job)
3. âœ… Integration with ONEKA database:
   - Read projects with status='ONGOING'
   - Extract satellite features
   - Run model prediction
   - Store risk score
4. âœ… Alert system: Email OAG when risk_score > 70

**Deliverable**: Automated prediction pipeline running on AWS

---

### Phase 4: Visualization (Weeks 6-7)

**Objective**: Build interactive map with Google 3D Tiles + satellite overlays.

**Tasks**:

1. âœ… Generate NDVI/SAR map tiles from GeoTIFFs
2. âœ… Upload tiles to S3 (XYZ tile structure)
3. âœ… Build CesiumJS viewer with:
   - Google 3D Tiles base layer
   - NDVI overlay (toggle)
   - SAR overlay (toggle)
   - Project pins (color-coded by risk)
4. âœ… Time-series chart component (Chart.js)
5. âœ… Project detail panel with ML prediction

**Deliverable**: Interactive web map at map.oneka.ai

---

### Phase 5: Demo Preparation (Week 8)

**Objective**: Prepare 3 hero projects for hackathon pitch.

**Tasks**:

1. âœ… Select demo projects:
   - Project A: LOW risk (on track, visible construction)
   - Project B: MEDIUM risk (delayed but progressing)
   - Project C: HIGH risk (ghost project, 92% probability)
2. âœ… Create time-lapse animations for each
3. âœ… Prepare talking points:
   - "Satellite data is immutable - we can prove construction never started"
   - "ML model trained on 30 historical projects with 85% accuracy"
   - "Early warning system can prevent fraud before it scales"
4. âœ… Practice 5-minute pitch

**Deliverable**: Demo script + presentation slides

---

## 6. Advanced Features (Post-MVP)

### 6.1 S-Curve Predictive Model

**Concept**: Infrastructure projects follow an "S-curve" spending pattern:

- Slow start (5-10% in Month 1-3)
- Rapid middle (60-70% in Months 4-18)
- Slow finish (20-30% in Months 19-24)

**Implementation**: Train regression model to predict expected NDVI/SAR values at each month based on contract value and project type. Flag deviations of >30% as anomalous.

### 6.2 Contractor Risk Profiling

**Concept**: Build contractor "reputation scores" based on historical satellite analysis of their past projects.

**Metric**:

```
Contractor Risk Score = (Ghost Projects / Total Projects) Ã— 100
```

Flag contractors with score > 20% for enhanced monitoring.

### 6.3 Sector-Specific Models

**Concept**: Train separate models for different project types:

- Health facilities (hospitals, dispensaries)
- Education (schools, classrooms)
- Roads (linear infrastructure, different signature)
- Water (boreholes, reservoirs)

Different projects have different construction timelines and satellite signatures.

---

## 7. Conclusion: The Power of Immutable Evidence

**The Paradigm Shift**:

Traditional audits rely on documents (invoices, reports, photos) that can be forged. **Satellite data cannot be forged**. Sentinel data is:

- âœ… **Immutable**: Copernicus archive is tamper-proof
- âœ… **Independent**: Not controlled by contractors or government
- âœ… **Historical**: We can go back in time to any project start date
- âœ… **Continuous**: No gaps in monitoring (every 6 days)

**ONEKA's Advantage**:

By training ML models on historical satellite data, ONEKA learns what "normal" construction looks like and can predict, with 85%+ accuracy, which projects will fail **within the first 6 months** - early enough to intervene and prevent losses that currently exceed KES 304 billion annually.

**For the Hackathon Pitch**:

> "While auditors wait 2 years to discover fraud, ONEKA's satellite-trained AI predicts ghost projects in real-time. We trained our model on 30 completed projects, learning the exact satellite signature of success vs abandonment. Now, within 6 months of any new project starting, we can tell you with 85% confidence if your KES 450 million hospital will ever be built - because the satellites don't lie, and physics doesn't negotiate."

---

**Document Version**: 1.0  
**Created**: January 29, 2026  
**Next Review**: After Phase 2 model training completion
